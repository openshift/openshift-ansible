---
- name: Fail if r_openshift_node_image_tag is not defined
  fail:
    msg: r_openshift_node_image_tag must be specified for this role
  when:
  - r_openshift_node_image_tag is not defined

# TODO: allow for overriding default ports where possible
- fail:
    msg: "SELinux is disabled, This deployment type requires that SELinux is enabled."
  when: >
    (not ansible_selinux or ansible_selinux.status != 'enabled') and
    r_openshift_node_deployment_type in ['enterprise', 'online', 'atomic-enterprise', 'openshift-enterprise']

- include: disable_swap.yml

# We have to add tuned-profiles in the same transaction otherwise we run into depsolving
# problems because the rpms don't pin the version properly. This was fixed in 3.1 packaging.
- name: Install Node package
  package:
    name: "{{ r_openshift_node_service_type }}-node{{ r_openshift_node_pkg_version | default('') | oo_image_tag_to_rpm_version(include_dash=True) }},tuned-profiles-{{ r_openshift_node_service_type }}-node{{ r_openshift_node_pkg_version | default('') | oo_image_tag_to_rpm_version(include_dash=True) }}"
    state: present
  when: not r_openshift_node_is_containerized | bool

- name: Check for tuned package
  command: rpm -q tuned
  args:
    warn: no
  register: tuned_installed
  changed_when: false
  failed_when: false

- name: Set atomic-guest tuned profile
  command: "tuned-adm profile atomic-guest"
  when: tuned_installed.rc == 0 and r_openshift_node_is_atomic | bool

- name: Install sdn-ovs package
  package:
    name: "{{ r_openshift_node_service_type }}-sdn-ovs{{ r_openshift_node_pkg_version | oo_image_tag_to_rpm_version(include_dash=True) }}"
    state: present
  when:
    - r_openshift_node_use_openshift_sdn | bool
    - not r_openshift_node_is_containerized | bool

- name: Install conntrack-tools package
  package:
    name: "conntrack-tools"
    state: present
  when: not r_openshift_node_is_containerized | bool

- name: Install the systemd units
  include: systemd_units.yml

# The atomic-openshift-node service will set this parameter on
# startup, but if the network service is restarted this setting is
# lost. Reference: https://bugzilla.redhat.com/show_bug.cgi?id=1372388
#
# Use lineinfile w/ a handler for this task until
# https://github.com/ansible/ansible/pull/24277 is included in an
# ansible release and we can use the sysctl module.
- name: Persist net.ipv4.ip_forward sysctl entry
  lineinfile: dest=/etc/sysctl.conf regexp='^net.ipv4.ip_forward' line='net.ipv4.ip_forward=1'
  notify:
    - reload sysctl.conf

- name: Start and enable openvswitch service
  systemd:
    name: openvswitch.service
    enabled: yes
    state: started
    daemon_reload: yes
  when:
    - r_openshift_node_is_containerized | bool
    - r_openshift_node_use_openshift_sdn | bool
  register: ovs_start_result
  until: not ovs_start_result | failed
  retries: 3
  delay: 30

- set_fact:
    ovs_service_status_changed: "{{ ovs_start_result | changed }}"

- file:
    dest: "{{ r_openshift_node_kubelet_args.config }}"
    state: directory
  when: r_openshift_node_kubelet_args is defined and 'config' in r_openshift_node_kubelet_args

# TODO: add the validate parameter when there is a validation command to run
- name: Create the Node config
  template:
    dest: "{{ r_openshift_node_config_base }}/node/node-config.yaml"
    src: node.yaml.v1.j2
    backup: true
    owner: root
    group: root
    mode: 0600
  notify:
    - restart node

- name: Configure AWS Cloud Provider Settings
  lineinfile:
    dest: /etc/sysconfig/{{ r_openshift_node_service_type }}-node
    regexp: "{{ item.regex }}"
    line: "{{ item.line }}"
    create: true
  with_items:
    - regex: '^AWS_ACCESS_KEY_ID='
      line: "AWS_ACCESS_KEY_ID={{ r_openshift_node_cloudprovider_aws_access_key | default('') }}"
    - regex: '^AWS_SECRET_ACCESS_KEY='
      line: "AWS_SECRET_ACCESS_KEY={{ r_openshift_node_cloudprovider_aws_secret_key | default('') }}"
  no_log: True
  when: r_openshift_node_cloudprovider_kind == 'aws' and r_openshift_node_cloudprovider_aws_access_key is defined and r_openshift_node_cloudprovider_aws_secret_key is defined
  notify:
    - restart node

- name: Configure Node Environment Variables
  lineinfile:
    dest: /etc/sysconfig/{{ r_openshift_node_service_type }}-node
    regexp: "^{{ item.key }}="
    line: "{{ item.key }}={{ item.value }}"
    create: true
  with_dict: "{{ r_openshift_node_env_vars }}"
  notify:
    - restart node

- name: NFS storage plugin configuration
  include: storage_plugins/nfs.yml
  tags:
    - nfs

- name: GlusterFS storage plugin configuration
  include: storage_plugins/glusterfs.yml
  when: "'glusterfs' in r_openshift_node_storage_plugin_deps"

- name: Ceph storage plugin configuration
  include: storage_plugins/ceph.yml
  when: "'ceph' in r_openshift_node_storage_plugin_deps"

- name: iSCSI storage plugin configuration
  include: storage_plugins/iscsi.yml
  when: "'iscsi' in r_openshift_node_storage_plugin_deps"

# Necessary because when you're on a node that's also a master the master will be
# restarted after the node restarts docker and it will take up to 60 seconds for
# systemd to start the master again
- name: Wait for master API to become available before proceeding
  # Using curl here since the uri module requires python-httplib2 and
  # wait_for port doesn't provide health information.
  command: >
    curl --silent --tlsv1.2 --cacert {{ r_openshift_node_config_base }}/node/ca.crt
    {{ r_openshift_node_master_api_url }}/healthz/ready
  args:
    # Disables the following warning:
    # Consider using get_url or uri module rather than running curl
    warn: no
  register: api_available_output
  until: api_available_output.stdout == 'ok'
  retries: 120
  delay: 1
  changed_when: false
  when: r_openshift_node_is_containerized | bool

- name: Start and enable node dep
  systemd:
    daemon_reload: yes
    name: "{{ r_openshift_node_service_type }}-node-dep"
    enabled: yes
    state: started
  when: r_openshift_node_is_containerized | bool


- name: Start and enable node
  systemd:
    name: "{{ r_openshift_node_service_type }}-node"
    enabled: yes
    state: started
    daemon_reload: yes
  register: node_start_result
  until: not node_start_result | failed
  retries: 1
  delay: 30
  ignore_errors: true

- name: Dump logs from node service if it failed
  command: journalctl --no-pager -n 100 -u {{ r_openshift_node_service_type }}-node
  when: node_start_result | failed

- name: Abort if node failed to start
  fail:
    msg: Node failed to start please inspect the logs and try again
  when: node_start_result | failed

- set_fact:
    node_service_status_changed: "{{ node_start_result | changed }}"
