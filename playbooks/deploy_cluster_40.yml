---
- name: run the init
  import_playbook: init/main.yml
  vars:
    l_init_fact_hosts: "nodes"
    l_openshift_version_set_hosts: "nodes"
    l_install_base_packages: True
    l_repo_hosts: "nodes"

# TODO(michaelgugino): break up the rest of this file into reusable chunks.
- name: Install nodes
  hosts: nodes
  roles:
  - role: container_runtime
  tasks:
  - import_role:
      name: container_runtime
      tasks_from: docker_storage_setup_overlay.yml
  - import_role:
      name: container_runtime
      tasks_from: extra_storage_setup.yml
  - import_role:
      name: container_runtime
      tasks_from: package_crio.yml
  - import_role:
      name: openshift_node40
      tasks_from: install.yml

- name: Config bootstrap node
  hosts: bootstrap
  tasks:
  # Bootstrap ignition file wants to set /home/core/.bash_history and requires a user to exist
  # to set permissions
  - name: FIXME Make sure core user exists
    user:
      name: core
  - import_role:
      name: openshift_node40
      tasks_from: config.yml
  - name: Wait for MCS endpoint to show up
    uri:
      url: "{{ mcd_endpoint }}/config/master"
      validate_certs: false
    delay: 10
    retries: 60
    register: mcs
    until:
    - "'status' in mcs"
    - mcs.status == 200
    ignore_errors: true
  - when: mcs is failed
    block:
    - name: Get node logs
      command: journalctl --no-pager -u bootkube
      register: bootkube_logs
      ignore_errors: true
    - name: Collect a list of containers
      command: crictl ps -a -q
      register: crictl_ps_output
    - name: Collect container logs
      command: "crictl logs {{ item }}"
      register: crictl_logs_output
      with_items: "{{ crictl_ps_output.stdout_lines }}"
      ignore_errors: true
    - debug:
        var: crictl_logs_output
    - debug:
        msg: "{{ bootkube_logs.stdout_lines }}"
    - fail:
        msg: MCS start failed.

- name: Start masters
  hosts: masters
  vars:
    openshift_bootstrap_endpoint: "https://{{ openshift_install_config['metadata']['name'] }}-api.{{ openshift_install_config['baseDomain'] }}:49500/config/master"
  tasks:
  - name: Wait for bootstrap endpoint to show up
    uri:
      url: "{{ openshift_bootstrap_endpoint }}"
      validate_certs: false
    delay: 10
    retries: 60
    register: result
    until:
    - "'status' in result"
    - result.status == 200
  - name: Make sure etcd user exists
    user:
      name: etcd
  - import_role:
      name: openshift_node40
      tasks_from: config.yml

- name: Start workers
  hosts: workers
  vars:
    openshift_bootstrap_endpoint: "https://{{ openshift_install_config['metadata']['name'] }}-api.{{ openshift_install_config['baseDomain'] }}:49500/config/worker"
  tasks:
  - name: Wait for bootstrap endpoint to show up
    uri:
      url: "{{ openshift_bootstrap_endpoint }}"
      validate_certs: false
    delay: 10
    retries: 60
    register: result
    until:
    - "'status' in result"
    - result.status == 200
  - import_role:
      name: openshift_node40
      tasks_from: config.yml

- name: Wait for nodes to become ready
  hosts: bootstrap
  tasks:
  - name: Wait for temporary control plane to show up
    oc_obj:
      state: list
      kind: pod
      namespace: kube-system
      kubeconfig: /opt/openshift/auth/kubeconfig
    register: control_plane_pods
    retries: 60
    delay: 10
    until:
    - "'results' in control_plane_pods and 'results' in control_plane_pods.results"
    - control_plane_pods.results.results[0]['items'] | length > 0
  - name: Wait for master nodes to show up
    oc_obj:
      state: list
      kind: node
      selector: "node-role.kubernetes.io/master"
      kubeconfig: /opt/openshift/auth/kubeconfig
    register: master_nodes
    retries: 60
    delay: 10
    until:
    - "'results' in master_nodes and 'results' in master_nodes.results"
    - master_nodes.results.results[0]['items'] | length > 0
  - name: Wait for bootkube service to finish
    service_facts: {}
    #10 mins to complete temp plane
    retries: 120
    delay: 5
    until: "'bootkube.service' not in ansible_facts.services"
    ignore_errors: true
  - name: Fetch kubeconfig for test container
    fetch:
      src: /opt/openshift/auth/kubeconfig
      dest: /tmp/artifacts/installer/auth/kubeconfig
      flat: yes

  - name: Wait for core operators to appear and complete
    oc_obj:
      state: list
      kind: ClusterVersion
      name: version
      kubeconfig: /opt/openshift/auth/kubeconfig
    register: cvo
    #Give CVO 10 mins to come up
    retries: 120
    delay: 5
    until:
    - "'results' in cvo"
    - "'results' in cvo.results"
    - cvo.results.results | length > 0
    - "'status' in cvo.results.results[0]"
    - "'conditions' in cvo.results.results[0]['status']"
    - cvo.results.results[0].status.conditions | selectattr('type', 'match', '^Available$') | map(attribute='status') | join | bool == True
    - cvo.results.results[0].status.conditions | selectattr('type', 'match', '^Failing$') | map(attribute='status') | join | bool == False
    - cvo.results.results[0].status.conditions | selectattr('type', 'match', '^Progressing$') | map(attribute='status') | join | bool == False
    ignore_errors: true

  - block:
    - name: Output CVO status
      oc_obj:
        state: list
        kind: ClusterVersion
        name: version
        kubeconfig: /opt/openshift/auth/kubeconfig
    - name: Output operators status
      oc_obj:
        state: list
        kind: ClusterOperator
        selector: ""
        kubeconfig: /opt/openshift/auth/kubeconfig
    - fail:
        msg: CVO didn't complete the install
    when: cvo.failed
